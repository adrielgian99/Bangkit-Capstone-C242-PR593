# -*- coding: utf-8 -*-
"""Obesity_Level_Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1E5_24duBDGo5E7Cs0z3KGnxwap0rh-mI
"""

from google.colab import files
uploaded = files.upload()

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import warnings
import re
import tensorflow as tf
import json
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.metrics import classification_report, accuracy_score
warnings.filterwarnings('ignore')
from sklearn.metrics import confusion_matrix, classification_report
from matplotlib import style
from tensorflow.keras.models import Model, load_model
# %matplotlib inline

# Input dataset
dataset_url = 'https://raw.githubusercontent.com/adrielgian99/Bangkit-Capstone-C242-PR593/machine_learning/Clean_Dataset/Data_Obesitas_new.csv'

df = pd.read_csv(dataset_url)
df.head()

df.info()

df.isna().sum()

print("Jumlah duplikasi: ", df.duplicated().sum())
df.describe()

selected_columns = ['Gender', 'family_history_with_overweight',	'FAVC',	'FCVC',	'NCP',	'CAEC',	'SMOKE',	'CH2O',	'SCC', 'FAF',	'TUE', 'CALC',	'MTRANS',	'NObeyesdad']

for column in selected_columns:
    print(f"Unique value frequencies for column '{column}':")
    print(df[column].value_counts())
    print("-" * 40)

"""MODEL KLASIFIKASI"""

label_encoder = LabelEncoder()
df['NObeyesdad'] = label_encoder.fit_transform(df['NObeyesdad'])

X = df.drop('NObeyesdad', axis=1)
y = df['NObeyesdad']

categorical_cols = X.select_dtypes(include=['object']).columns
numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns

numerical_transformer = StandardScaler()
categorical_transformer = OneHotEncoder(handle_unknown='ignore')
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, numerical_cols),
        ('cat', categorical_transformer, categorical_cols)
    ]
)

X = preprocessor.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Check the processed data shapes
{
    "X_train_shape": X_train.shape,
    "X_test_shape": X_test.shape,
    "y_train_shape": y_train.shape,
    "y_test_shape": y_test.shape
}

model = tf.keras.Sequential([
    tf.keras.layers.Input(shape=(X_train.shape[1],)),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(len(label_encoder.classes_), activation='softmax')
])

model.summary()

model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

history = model.fit(X_train, y_train, epochs=30, batch_size=32, validation_split=0.2)

test_loss, test_acc = model.evaluate(X_test, y_test)
print(f"Test accuracy: {test_acc:.2f}")

y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)

conf_matrix = confusion_matrix(y_test, y_pred_classes)

plt.figure(figsize=(10, 6))
plt.plot(history.history['loss'], label='Training Loss', color='blue')
plt.plot(history.history['val_loss'], label='Validation Loss', color='orange')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Validation Loss Over Epochs')
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(10, 6))
plt.plot(history.history['accuracy'], label='Training accuracy', color='blue')
plt.plot(history.history['val_accuracy'], label='Validation accuracy', color='orange')
plt.xlabel('accuracy')
plt.ylabel('Loss')
plt.title('Training and Validation accuracy Over Epochs')
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Reds', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()

predicted_labels = label_encoder.inverse_transform(y_pred_classes)

true_labels = label_encoder.inverse_transform(y_test)
predicted_labels = label_encoder.inverse_transform(y_pred_classes)

results = pd.DataFrame({
    'Actual': true_labels,
    'Predicted': predicted_labels
})

print("Hasil Prediksi dalam Bentuk Kata:\n")
print(results.head(10))

print("\nClassification Report:\n")
print(classification_report(true_labels, predicted_labels))

"""Mengubah Model Ke TFLite"""

model.save("model.h5")

# Install tensorflowjs

!pip install tensorflowjs

# mengubah model.h5 kedalam bentuk json
!tensorflowjs_converter --input_format=keras \
model.h5 \
./tfjs_model

# Load the trained model
model = load_model('model.h5')

# Example new data for prediction
new_data = pd.DataFrame({
    'Gender' : ['pria'],
    'Age': [22],
    'Height' : [170],
    'Weight' : [95.0],
    'family_history_with_overweight' : ['iya'],
    'FAVC' : ['iya'],
    'FCVC' : ['kadang-kadang'],
    'NCP' : ['tiga kali'],
    'CAEC' : ['kadang-kadang'],
    'SMOKE' : ['tidak'],
    'CH2O' : ['lebih dari 2 liter'],
    'SCC' : ['tidak'],
    'FAF' : ['kisaran 1-2 hari'],
    'TUE' :	['lebih dari 5 jam'],
    'CALC' : ['tidak'],
    'MTRANS' : ['mobil']
})

X_new = preprocessor.transform(new_data)

predictions = model.predict(X_new)
predicted_labels = np.argmax(predictions, axis=1)
predicted_labels = label_encoder.inverse_transform(predicted_labels)

print("Predicted Labels:", predicted_labels)